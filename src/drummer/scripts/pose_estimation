#!/usr/bin/env python3
##### Source: https://automaticaddison.com/how-to-perform-pose-estimation-using-an-aruco-marker/ #####

from inspect import ArgSpec 
import cv2 as cv
import numpy as np
from scipy.spatial.transform import Rotation
import sys
import os

# Ros imports
from geometry_msgs.msg import PoseStamped
import tf2_ros
import rospy
import imutils
 
# Local imports
from drummer.msg import PoseStampedArray


# Dictionary that was used to generate the ArUco marker
aruco_dictionary_name = "DICT_4X4_100"
 
# The different ArUco dictionaries built into the OpenCV library. 
ARUCO_DICT = {
  "DICT_4X4_50": cv.aruco.DICT_4X4_50,
  "DICT_4X4_100": cv.aruco.DICT_4X4_100,
  "DICT_4X4_250": cv.aruco.DICT_4X4_250,
  "DICT_4X4_1000": cv.aruco.DICT_4X4_1000,
  "DICT_5X5_50": cv.aruco.DICT_5X5_50,
  "DICT_5X5_100": cv.aruco.DICT_5X5_100,
  "DICT_5X5_250": cv.aruco.DICT_5X5_250,
  "DICT_5X5_1000": cv.aruco.DICT_5X5_1000,
  "DICT_6X6_50": cv.aruco.DICT_6X6_50,
  "DICT_6X6_100": cv.aruco.DICT_6X6_100,
  "DICT_6X6_250": cv.aruco.DICT_6X6_250,
  "DICT_6X6_1000": cv.aruco.DICT_6X6_1000,
  "DICT_7X7_50": cv.aruco.DICT_7X7_50,
  "DICT_7X7_100": cv.aruco.DICT_7X7_100,
  "DICT_7X7_250": cv.aruco.DICT_7X7_250,
  "DICT_7X7_1000": cv.aruco.DICT_7X7_1000,
  "DICT_ARUCO_ORIGINAL": cv.aruco.DICT_ARUCO_ORIGINAL
}
 
# Side length of the ArUco marker in meters 
aruco_marker_side_length = 0.08
 
# Calibration parameters yaml file
SCRIPTDIR = os.path.dirname(__file__)
camera_calibration_parameters_filename = os.path.join(SCRIPTDIR, '..', '..', '..', 'cal.yaml')

instruments_dictionary = {
35: 'Bass Drum 2',
36: 'Bass Drum 1',
37: 'Side Stick',
38: 'Snare Drum 1',
39: 'Hand Clap',
40: 'Snare Drum 2',
41: 'Low Tom 2',
42: 'Closed Hi-hat',
43: 'Low Tom 1',
44: 'Pedal Hi-hat',
45: 'Mid Tom 2',
46: 'Open Hi-hat',
47: 'Mid Tom 1',
48: 'High Tom 2',
49: 'Crash Cymbal 1',
50: 'High Tom 1',
51: 'Ride Cymbal 1',
52: 'Chinese Cymbal',
53: 'Ride Bell',
54: 'Tambourine',
55: 'Splash Cymbal',
56: 'Cowbell',
57: 'Crash Cymbal 2',
58: 'Vibra Slap',

59: 'Ride Cymbal 2',
60: 'High Bongo',
61: 'Low Bongo',
62: 'Mute High Conga',
63: 'Open High Conga',
64: 'Low Conga',
65: 'High Timbale',
66: 'Low Timbale',
67: 'High Agogo',
68: 'Low Agogo',
69: 'Cabasa',
70: 'Maracas',
71: 'Short Whistle',
72: 'Long Whistle',
73: 'Short Guiro',
74: 'Long Guiro',
75: 'Claves',
76: 'High Wood Block',
77: 'Low Wood Block',
78: 'Mute Cuica',
79: 'Open Cuica',
80: 'Mute Triangle',
81: 'Open Triangle' 
}
 
   
if __name__ == '__main__':
  """
  Main method of the program.
  """

  rospy.init_node('aruco_tf_broadcaster')
  print(__doc__)

  # Check that we have a valid ArUco marker
  if ARUCO_DICT.get(aruco_dictionary_name, None) is None:
    print("[INFO] ArUCo tag of '{}' is not supported".format(
      ArgSpec["type"]))
    sys.exit(0)
 
  # Load the camera parameters from the saved file
  cv_file = cv.FileStorage(
    camera_calibration_parameters_filename, cv.FILE_STORAGE_READ) 
  mtx = cv_file.getNode('K').mat()
  dst = cv_file.getNode('D').mat()
  cv_file.release()
     
  # Load the ArUco dictionary
  print("[INFO] detecting '{}' markers...".format(
    aruco_dictionary_name))
  this_aruco_dictionary = cv.aruco.Dictionary_get(ARUCO_DICT[aruco_dictionary_name])
  this_aruco_parameters = cv.aruco.DetectorParameters_create()
   
  # Start the video stream
  cap = cv.VideoCapture(6)   #'6' it is for the robominds camera at the ur10e
  
  cap.set(cv.CAP_PROP_FRAME_WIDTH, 1280)
  cap.set(cv.CAP_PROP_FRAME_HEIGHT, 720)

  aruco_poses_pub = rospy.Publisher('aruco_poses', PoseStampedArray, queue_size=1, latch=False)
  while(not rospy.is_shutdown()):
  
    # Capture frame-by-frame
    # This method returns True/False as well
    # as the video frame.
    ret, frame = cap.read() 
    # frame = imutils.resize(frame, width=1280, height=720)
    # frame = cv.rotate(frame, cv.ROTATE_180) # TODO: check if we need thi sor not
  
    # Detect ArUco markers in the video frame
    (corners, marker_ids, rejected) = cv.aruco.detectMarkers(
      frame, this_aruco_dictionary, parameters=this_aruco_parameters,
      cameraMatrix=mtx, distCoeff=dst)
       
    # Check that at least one ArUco marker was detected
    if marker_ids is not None:
 
      # Draw a square around detected markers in the video frame
      cv.aruco.drawDetectedMarkers(frame, corners, marker_ids)
       
      # Get the rotation and translation vectors
      rvecs, tvecs, obj_points = cv.aruco.estimatePoseSingleMarkers(
        corners,
        aruco_marker_side_length,
        mtx,
        dst)
         
      ##### Prepare aruco poses for publishing #####
      # The pose of the marker is with respect to the camera lens frame.
      # Imagine you are looking through the camera viewfinder, 
      # the camera lens frame's:
      # x-axis points to the right
      # y-axis points straight down towards your toes
      # z-axis points straight ahead away from your eye, out of the camera
      aruco_poses = PoseStampedArray()
      for i, marker_id in enumerate(marker_ids):
       
        # Store the rotation information
        rotation_matrix = np.eye(4)
        rotation_matrix[0:3, 0:3] = cv.Rodrigues(np.array(rvecs[i][0]))[0]
        r = Rotation.from_matrix(rotation_matrix[0:3, 0:3])
        quat = r.as_quat()   

        # Draw the axes on the marker
        cv.aruco.drawAxis(frame, mtx, dst, rvecs[i], tvecs[i], 0.03)
         
        if marker_id[0] not in instruments_dictionary:
          rospy.logdebug(f'AruCo id {marker_id[0]} not in instruments dictionary.')
        else:
          # Create our pose object of the aruco code
          aruco_pose = PoseStamped()
          aruco_pose.header.frame_id = instruments_dictionary[marker_id[0]]
          aruco_pose.header.stamp = rospy.Time.now()
          aruco_pose.pose.position.x = tvecs[i][0][0]
          aruco_pose.pose.position.y = tvecs[i][0][1]
          aruco_pose.pose.position.z = tvecs[i][0][2]
          aruco_pose.pose.orientation.x = quat[0]
          aruco_pose.pose.orientation.y = quat[1]
          aruco_pose.pose.orientation.z = quat[2]
          aruco_pose.pose.orientation.w = quat[3]
          aruco_poses.poses.append(aruco_pose)

          # rospy.loginfo(aruco_pose)

      # #### Hard coded positions for testing purposes #####
      # aruco_pose = PoseStamped()
      # aruco_pose.header.frame_id = 'Fake'
      # aruco_pose.header.stamp = rospy.Time.now()
      # aruco_pose.pose.position.x = 0
      # aruco_pose.pose.position.y = 0.0
      # aruco_pose.pose.position.z = 0.80
      # aruco_pose.pose.orientation.x = 0
      # aruco_pose.pose.orientation.y = 0
      # aruco_pose.pose.orientation.z = 0
      # aruco_pose.pose.orientation.w = 1
      # aruco_poses.poses.append(aruco_pose)


      aruco_poses_pub.publish(aruco_poses)
     
    # Display the resulting frame
    # frame = imutils.resize(frame)
    frame = cv.rotate(frame, cv.ROTATE_180)
    cv.imshow('frame', frame)
          
    # If "q" is pressed on the keyboard, 
    # exit this loop
    if cv.waitKey(1) & 0xFF == ord('q'):
      break
  
  # Close down the video stream
  cap.release()
  cv.destroyAllWindows()